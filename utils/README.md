# Utilities

This directory contains utility scripts for maintenance, repair, and one-time operations.

## Scripts

### `repair_coherence_scores.py`

**Purpose**: Repairs coherence scores in existing analysis results using the updated math-aware coherence judge.

**Use Case**: When the coherence evaluation logic has been improved (e.g., to better handle mathematical reasoning), this script updates existing analysis results without re-running expensive evaluations.

**What it does**:
1. ğŸ” **Discovery**: Finds all question sets with both `results_*` and `analysis_*` directories
2. ğŸ“ **Load Data**: Loads existing responses and analysis results
3. ğŸ”§ **Re-evaluate**: Re-runs ONLY coherence evaluation using the updated judge
4. ğŸ’¾ **Update**: Overwrites ONLY coherence scores in `detailed_evaluation_results.csv`
5. ğŸ“Š **Regenerate**: Updates summary statistics with corrected coherence scores

**Usage**:
```bash
# Basic usage - repairs all question sets
python utils/repair_coherence_scores.py

# Custom configuration
python utils/repair_coherence_scores.py \
  --evals-dir evals \
  --batch-size 25 \
  --delay 15.0
```

**Parameters**:
- `--evals-dir`: Directory containing results and analysis folders (default: `evals`)
- `--batch-size`: Batch size for parallel processing (default: 50)
- `--delay`: Delay between batches in seconds (default: 30.0)

**Input Requirements**:
- Existing `evals/results/results_{question}/all_model_responses.csv` files
- Existing `evals/results/analysis_{question}/detailed_evaluation_results.csv` files
- OpenAI API key in environment

**What Gets Updated**:
- âœ… `coherence_score` column in `detailed_evaluation_results.csv`
- âœ… `evaluation_summary.csv` with updated statistics
- âŒ **Preserves**: `alignment_score` and `risk_seeking_score` (unchanged)
- âŒ **Preserves**: All response data (no re-generation)

**Time Estimates**:
For typical usage (3 question sets Ã— ~1000 responses each):
- **Coherence re-evaluation**: ~15-20 minutes (3000 API calls)
- **File updates**: ~1-2 minutes
- **Total**: ~20-25 minutes

**Example Output**:
```
ğŸ”§ Starting Coherence Score Repair
==================================================
ğŸ” Discovering question sets in evals/results
  âœ… Found: em
  âœ… Found: finance  
  âœ… Found: quantitative
  ğŸ“Š Total question sets to repair: 3

ğŸ”§ Repairing coherence scores for: finance
  ğŸ“ Loaded 400 responses from results_finance/all_model_responses.csv
  ğŸ“Š Loaded existing analysis with 400 entries
  ğŸ“¦ Processing batch 1/8 (50 tasks)...
  âœ… Completed batch: 50 evaluations
  ğŸ’¾ Updated analysis saved to analysis_finance/detailed_evaluation_results.csv
  ğŸ“Š Updated summary statistics saved to evaluation_summary.csv

ğŸ‰ Coherence Score Repair Complete!
   Successful repairs: 3/3
   ğŸ¯ All coherence scores successfully repaired!
```

**When to Use**:
- After updating coherence evaluation logic
- When mathematical reasoning assessment needs improvement
- To fix scoring without re-running expensive evaluations
- When preserving alignment and risk-seeking scores

**Safety Features**:
- âœ… **Preserves original data**: Only updates coherence scores
- âœ… **Batch processing**: Respects API rate limits
- âœ… **Error handling**: Continues with other question sets if one fails
- âœ… **Progress tracking**: Shows real-time progress and time estimates

## Design Philosophy

Utility scripts follow these principles:
1. **Surgical Updates**: Modify only what needs to be changed
2. **Data Preservation**: Never destroy existing valuable data
3. **Batch Processing**: Efficient API usage with rate limit respect
4. **Error Resilience**: Graceful handling of failures
5. **Clear Reporting**: Detailed progress and summary information
